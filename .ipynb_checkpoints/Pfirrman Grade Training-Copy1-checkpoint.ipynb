{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74443269-c41a-44b0-8dd3-4d3c9b7078ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5c5a47-85f0-4f44-aff6-e9e8d52c0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"all_images\"\n",
    "image_list = []\n",
    "label_list = []\n",
    "pfirrman_grades = []\n",
    "df = pd.read_csv('AggregatePTData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2cad52-3618-41b3-9b41-d1d049de2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_filename in os.listdir(image_folder):\n",
    "    if image_filename.endswith(\".png\"):\n",
    "        image = Image.open(os.path.join(image_folder, image_filename))\n",
    "        # Resize image to 224x224 pixels\n",
    "        image = image.resize((224,224))\n",
    "        # Convert image to RGB\n",
    "        image = image.convert(\"RGB\")\n",
    "        # Convert the image to numpy array\n",
    "        image_array = np.array(image)\n",
    "        # Normalize array\n",
    "        image_array = preprocess_input(image_array)\n",
    "        image_list.append(image_array)\n",
    "        \n",
    "        row = df[df['file_name'] == image_filename]\n",
    "        pfirrman_grade = row.iloc[0]['Pfirrman grade']\n",
    "        pfirrman_grades.append(pfirrman_grade)\n",
    "\n",
    "\n",
    "image_list_np = np.array(image_list)\n",
    "pfirrman_grades_np = np.array(pfirrman_grades)\n",
    "pfirrman_grades_np = np.round(pfirrman_grades_np).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72265a16-e366-41d1-b73b-a28336cf7d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n",
      "361\n"
     ]
    }
   ],
   "source": [
    "print(len(image_list_np))\n",
    "print(len(pfirrman_grades_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3f80ca-a2bd-4e46-a786-de1214b5c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce dimensions\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(5, activation='softmax')(x)  # Output layer for regression (linear activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1ff725-b21f-4db3-afd2-7bd4f51c9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c420a1-67bc-4e16-8ec2-b25d71ffd6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.3358 - loss: 3.5021 - val_accuracy: 0.3014 - val_loss: 4.1628\n",
      "Epoch 2/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5264 - loss: 1.7495 - val_accuracy: 0.4247 - val_loss: 3.4512\n",
      "Epoch 3/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6519 - loss: 0.9723 - val_accuracy: 0.3836 - val_loss: 2.7100\n",
      "Epoch 4/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.8089 - loss: 0.7467 - val_accuracy: 0.3836 - val_loss: 2.0147\n",
      "Epoch 5/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.8928 - loss: 0.5088 - val_accuracy: 0.3699 - val_loss: 1.7307\n",
      "Epoch 6/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9021 - loss: 0.4267 - val_accuracy: 0.3425 - val_loss: 1.7785\n",
      "Epoch 7/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9460 - loss: 0.3451 - val_accuracy: 0.3699 - val_loss: 2.0200\n",
      "Epoch 8/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9832 - loss: 0.2286 - val_accuracy: 0.3562 - val_loss: 1.9815\n",
      "Epoch 9/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9750 - loss: 0.1924 - val_accuracy: 0.3288 - val_loss: 2.1278\n",
      "Epoch 10/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9892 - loss: 0.1561 - val_accuracy: 0.3288 - val_loss: 2.1412\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    image_list_np,            # Input images\n",
    "    pfirrman_grades_np,       # Target labels (Pfirrman grades)\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,     # Split 20% of data for validation\n",
    "    verbose=1                 # Set to 1 to see training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf8af678-130a-4b8a-ad5e-23dc198730b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Predicted Pfirrman grade: 2\n"
     ]
    }
   ],
   "source": [
    "test_image_path = 'all_images/47_t2.png'\n",
    "\n",
    "# Load, resize, and preprocess the test image\n",
    "img = Image.open(test_image_path).convert('RGB')\n",
    "img_resized = img.resize((224, 224))\n",
    "img_array = np.array(img_resized)\n",
    "\n",
    "# Preprocess the image for ResNet50\n",
    "img_preprocessed = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "img_preprocessed = np.expand_dims(img_preprocessed, axis=0)  # Add batch dimension\n",
    "\n",
    "# Run the prediction\n",
    "predicted_probabilities = model.predict(img_preprocessed)\n",
    "predicted_class = np.argmax(predicted_probabilities) + 1  # Add 1 if classes are 1-5\n",
    "\n",
    "print(f\"Predicted Pfirrman grade: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad646b-7546-4d27-9208-344aaf9add53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e59ff-6e75-464b-968d-4f9f24745790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24579fa5-8221-4aab-b9f5-37d38d93ae5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
