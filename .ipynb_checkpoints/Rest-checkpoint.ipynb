{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74443269-c41a-44b0-8dd3-4d3c9b7078ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5c5a47-85f0-4f44-aff6-e9e8d52c0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"all_images\"\n",
    "image_list = []\n",
    "label_list = []\n",
    "pfirrman_grades = []\n",
    "modic_types = []\n",
    "up_endplates = []\n",
    "low_endplates = []\n",
    "disc_herniation = []\n",
    "disc_narrowing = []\n",
    "disc_bulging = []\n",
    "spondylolisthesis = []\n",
    "\n",
    "df = pd.read_csv('AggregatePTData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2cad52-3618-41b3-9b41-d1d049de2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_filename in os.listdir(image_folder):\n",
    "    if image_filename.endswith(\".png\"):\n",
    "        image = Image.open(os.path.join(image_folder, image_filename))\n",
    "        # Resize image to 224x224 pixels\n",
    "        image = image.resize((224,224))\n",
    "        # Convert image to RGB\n",
    "        image = image.convert(\"RGB\")\n",
    "        # Convert the image to numpy array\n",
    "        image_array = np.array(image)\n",
    "        # Normalize array\n",
    "        image_array = preprocess_input(image_array)\n",
    "        image_list.append(image_array)\n",
    "        \n",
    "        row = df[df['file_name'] == image_filename]\n",
    "        pfirrman_grade = row.iloc[0]['Pfirrman grade']\n",
    "        pfirrman_grades.append(pfirrman_grade)\n",
    "        modic = row.iloc[0]['Modic']\n",
    "        modic_types.append(modic)\n",
    "        up = row.iloc[0]['UP endplate']\n",
    "        up_endplates.append(up)\n",
    "        low = row.iloc[0]['LOW endplate']\n",
    "        low_endplates.append(low)\n",
    "        herniation = row.iloc[0]['Disc herniation']\n",
    "        disc_herniation.append(herniation)\n",
    "        narrowing = row.iloc[0]['Disc narrowing']\n",
    "        disc_narrowing.append(narrowing)\n",
    "        bulging = row.iloc[0]['Disc bulging']\n",
    "        disc_bulging.append(bulging)\n",
    "        spondy = row.iloc[0]['Spondylolisthesis']\n",
    "        spondylolisthesis.append(spondy)\n",
    "\n",
    "image_list_np = np.array(image_list)\n",
    "pfirrman_grades_np = np.array(pfirrman_grades)\n",
    "pfirrman_grades_np = np.round(pfirrman_grades_np).astype(int) - 1\n",
    "modic_types_np = np.array(modic_types)\n",
    "modic_types_np = np.round(modic_types_np).astype(int)\n",
    "up_endplates_np = np.array(up_endplates)\n",
    "up_endplates_np = np.round(up_endplates_np).astype(int)\n",
    "low_endplates_np = np.array(low_endplates)\n",
    "low_endplates_np = np.round(low_endplates_np).astype(int)\n",
    "disc_herniation_np = np.array(disc_herniation)\n",
    "disc_herniation_np = np.round(disc_herniation_np).astype(int)\n",
    "disc_narrowing_np = np.array(disc_narrowing)\n",
    "disc_narrowing_np = np.round(disc_narrowing_np).astype(int)\n",
    "disc_bulging_np = np.array(disc_bulging)\n",
    "disc_bulging_np = np.round(disc_bulging_np).astype(int)\n",
    "spondylolisthesis_np = np.array(spondylolisthesis)\n",
    "spondylolisthesis_np = np.round(spondylolisthesis_np).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72265a16-e366-41d1-b73b-a28336cf7d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3f80ca-a2bd-4e46-a786-de1214b5c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce dimensions\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "pfirrman_predictions = Dense(5, activation='softmax', name='pfirrman_output')(x)\n",
    "modic_predictions = Dense(3, activation='softmax', name='modic_output')(x)\n",
    "up_predictions = Dense(1, activation='sigmoid', name='up_output')(x)\n",
    "low_predictions = Dense(1, activation='sigmoid', name='low_output')(x)\n",
    "herniation_predictions = Dense(1, activation='sigmoid', name='herniation_output')(x)\n",
    "narrowing_predictions = Dense(1, activation='sigmoid', name='narrowing_output')(x)\n",
    "bulging_predictions = Dense(1, activation='sigmoid', name='bulging_output')(x)\n",
    "spondy_predictions = Dense(1, activation='sigmoid', name='spondy_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1ff725-b21f-4db3-afd2-7bd4f51c9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=[pfirrman_predictions, modic_predictions, up_predictions, low_predictions, herniation_predictions, narrowing_predictions, bulging_predictions, spondy_predictions])\n",
    "model.compile(optimizer='adam', loss={\n",
    "        'pfirrman_output': 'sparse_categorical_crossentropy', \n",
    "        'modic_output': 'sparse_categorical_crossentropy',\n",
    "        'up_output': 'binary_crossentropy',\n",
    "        'low_output': 'binary_crossentropy',\n",
    "        'herniation_output': 'binary_crossentropy',\n",
    "        'narrowing_output': 'binary_crossentropy',\n",
    "        'bulging_output': 'binary_crossentropy',\n",
    "        'spondy_output': 'binary_crossentropy'\n",
    "    },          \n",
    "    metrics={\n",
    "        'pfirrman_output': 'accuracy',\n",
    "        'modic_output': 'accuracy',\n",
    "        'up_output': 'accuracy',\n",
    "        'low_output': 'accuracy',\n",
    "        'herniation_output': 'accuracy',\n",
    "        'narrowing_output': 'accuracy',\n",
    "        'bulging_output': 'accuracy',\n",
    "        'spondy_output': 'accuracy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54efd51-33d1-41b4-a847-a3eafa79c5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c420a1-67bc-4e16-8ec2-b25d71ffd6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_list_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Input images\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpfirrman_grades_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodic_types_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup_endplates_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_endplates_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisc_herniation_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisc_narrowing_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisc_bulging_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspondylolisthesis_np\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Split 20% of data for validation\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Set to 1 to see training progress\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:694\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[1;34m(target, output, from_logits)\u001b[0m\n\u001b[0;32m    691\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    698\u001b[0m     )\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 5)"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    image_list_np,            # Input images\n",
    "    [pfirrman_grades_np, modic_types_np, up_endplates_np, low_endplates_np, disc_herniation_np, disc_narrowing_np, disc_bulging_np, spondylolisthesis_np],\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,     # Split 20% of data for validation\n",
    "    verbose=1                 # Set to 1 to see training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8af678-130a-4b8a-ad5e-23dc198730b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'all_images/10_t2.png'\n",
    "\n",
    "# Load, resize, and preprocess the test image\n",
    "img = Image.open(test_image_path).convert('RGB')\n",
    "img_resized = img.resize((224, 224))\n",
    "img_array = np.array(img_resized)\n",
    "\n",
    "# Preprocess the image for ResNet50\n",
    "img_preprocessed = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "img_preprocessed = np.expand_dims(img_preprocessed, axis=0)  # Add batch dimension\n",
    "\n",
    "# Run the prediction\n",
    "predicted_probabilities = model.predict(img_preprocessed)\n",
    "predicted_pfirrman = np.argmax(predicted_probabilities[0]) + 1  # Add 1 if classes are 1-5\n",
    "predicted_modic = np.argmax(predicted_probabilities[1])\n",
    "print(f\"Predicted Pfirrman grade: {predicted_pfirrman}\")\n",
    "print(f\"Predicted Modic: {predicted_modic}\")\n",
    "print(f\"Probability of Up-Endplate: {predicted_probabilities[2][0][0]}\")\n",
    "print(f\"Probability of Low-Endplate: {predicted_probabilities[3][0][0]}\")\n",
    "print(f\"Probability of Disc-Herniation: {predicted_probabilities[4][0][0]}\")\n",
    "print(f\"Probability of Disc-Narrowing: {predicted_probabilities[5][0][0]}\")\n",
    "print(f\"Probability of Disc-Bulging: {predicted_probabilities[6][0][0]}\")\n",
    "print(f\"Probability of Spondylolisthesis: {predicted_probabilities[7][0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad646b-7546-4d27-9208-344aaf9add53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e59ff-6e75-464b-968d-4f9f24745790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24579fa5-8221-4aab-b9f5-37d38d93ae5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
