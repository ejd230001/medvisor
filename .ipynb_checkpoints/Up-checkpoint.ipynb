{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74443269-c41a-44b0-8dd3-4d3c9b7078ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5c5a47-85f0-4f44-aff6-e9e8d52c0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"all_images\"\n",
    "image_list = []\n",
    "label_list = []\n",
    "pfirrman_grades = []\n",
    "modic_types = []\n",
    "up_endplates = []\n",
    "df = pd.read_csv('AggregatePTData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2cad52-3618-41b3-9b41-d1d049de2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_filename in os.listdir(image_folder):\n",
    "    if image_filename.endswith(\".png\"):\n",
    "        image = Image.open(os.path.join(image_folder, image_filename))\n",
    "        # Resize image to 224x224 pixels\n",
    "        image = image.resize((224,224))\n",
    "        # Convert image to RGB\n",
    "        image = image.convert(\"RGB\")\n",
    "        # Convert the image to numpy array\n",
    "        image_array = np.array(image)\n",
    "        # Normalize array\n",
    "        image_array = preprocess_input(image_array)\n",
    "        image_list.append(image_array)\n",
    "        \n",
    "        row = df[df['file_name'] == image_filename]\n",
    "        pfirrman_grade = row.iloc[0]['Pfirrman grade']\n",
    "        pfirrman_grades.append(pfirrman_grade)\n",
    "        modic = row.iloc[0]['Modic']\n",
    "        modic_types.append(modic)\n",
    "        up = row.iloc[0]['UP endplate']\n",
    "        up_endplates.append(up)\n",
    "\n",
    "image_list_np = np.array(image_list)\n",
    "pfirrman_grades_np = np.array(pfirrman_grades)\n",
    "pfirrman_grades_np = np.round(pfirrman_grades_np).astype(int) - 1\n",
    "modic_types_np = np.array(modic_types)\n",
    "modic_types_np = np.round(modic_types_np).astype(int)\n",
    "up_endplates_np = np.array(up_endplates)\n",
    "up_endplates_np = np.round(up_endplates_np).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72265a16-e366-41d1-b73b-a28336cf7d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1\n",
      " 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
      " 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f80ca-a2bd-4e46-a786-de1214b5c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce dimensions\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "pfirrman_predictions = Dense(5, activation='softmax', name='pfirrman_output')(x)\n",
    "modic_predictions = Dense(3, activation='softmax', name='modic_output')(x)\n",
    "up_predictions = Dense(1, activation='sigmoid', name='up_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ff725-b21f-4db3-afd2-7bd4f51c9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=[pfirrman_predictions, modic_predictions, up_predictions])\n",
    "model.compile(optimizer='adam', loss={\n",
    "        'pfirrman_output': 'sparse_categorical_crossentropy', \n",
    "        'modic_output': 'sparse_categorical_crossentropy',\n",
    "        'up_output': 'binary_crossentropy'\n",
    "    },          \n",
    "    metrics={\n",
    "        'pfirrman_output': 'accuracy',\n",
    "        'modic_output': 'accuracy',\n",
    "        'up_output': 'accuracy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54efd51-33d1-41b4-a847-a3eafa79c5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c420a1-67bc-4e16-8ec2-b25d71ffd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    image_list_np,            # Input images\n",
    "    [pfirrman_grades_np, modic_types_np, up_endplates_np],\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,     # Split 20% of data for validation\n",
    "    verbose=1                 # Set to 1 to see training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8af678-130a-4b8a-ad5e-23dc198730b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'all_images/51_t1.png'\n",
    "\n",
    "# Load, resize, and preprocess the test image\n",
    "img = Image.open(test_image_path).convert('RGB')\n",
    "img_resized = img.resize((224, 224))\n",
    "img_array = np.array(img_resized)\n",
    "\n",
    "# Preprocess the image for ResNet50\n",
    "img_preprocessed = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "img_preprocessed = np.expand_dims(img_preprocessed, axis=0)  # Add batch dimension\n",
    "\n",
    "# Run the prediction\n",
    "predicted_probabilities = model.predict(img_preprocessed)\n",
    "predicted_pfirrman = np.argmax(predicted_probabilities[0]) + 1  # Add 1 if classes are 1-5\n",
    "predicted_modic = np.argmax(predicted_probabilities[1])\n",
    "print(f\"Predicted Pfirrman grade: {predicted_pfirrman}\")\n",
    "print(f\"Predicted Modic: {predicted_modic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad646b-7546-4d27-9208-344aaf9add53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e59ff-6e75-464b-968d-4f9f24745790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24579fa5-8221-4aab-b9f5-37d38d93ae5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
