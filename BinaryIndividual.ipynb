{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfb40e2-e0e0-487d-bb36-93b3dcf31b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3d37ebd-3ecd-4d43-be66-5b212b139b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels have been mapped to each image and stored in the corresponding lists.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = 'radiological_gradings.csv'\n",
    "radiological_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Initialize lists for each label\n",
    "pfirrman_grades = []\n",
    "modic_types = []\n",
    "up_endplates = []\n",
    "low_endplates = []\n",
    "disc_herniation = []\n",
    "disc_narrowing = []\n",
    "disc_bulging = []\n",
    "spondylolisthesis = []\n",
    "image_list = []  # For storing image data\n",
    "image_names = []\n",
    "\n",
    "# Directory containing the disc images\n",
    "image_dir = \"split_discs\"\n",
    "\n",
    "# Loop through each image in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # Parse patient number and IVD label from the filename\n",
    "        base_name = filename.replace(\".png\", \"\")\n",
    "        \n",
    "        # Split the filename and handle cases with additional parts\n",
    "        parts = base_name.split(\"_\")\n",
    "        patient_id = int(parts[0])           # First part is always the patient ID\n",
    "        scan_type = parts[-2]                # Second last part is the scan type (t1/t2)\n",
    "        ivd_label = int(parts[-1].replace(\"disc\", \"\"))  # Last part is the disc label\n",
    "        \n",
    "        # Find the corresponding row in the CSV\n",
    "        row = radiological_data[(radiological_data['Patient'] == patient_id) &\n",
    "                                (radiological_data['IVD label'] == ivd_label)]\n",
    "        \n",
    "        # Ensure the row exists and extract label values\n",
    "        if not row.empty:\n",
    "            # Append each label to its respective list\n",
    "            modic_types.append(row['Modic'].values[0])\n",
    "            up_endplates.append(row['UP endplate'].values[0])\n",
    "            low_endplates.append(row['LOW endplate'].values[0])\n",
    "            spondylolisthesis.append(row['Spondylolisthesis'].values[0])\n",
    "            disc_herniation.append(row['Disc herniation'].values[0])\n",
    "            disc_narrowing.append(row['Disc narrowing'].values[0])\n",
    "            disc_bulging.append(row['Disc bulging'].values[0])\n",
    "            pfirrman_grades.append(row['Pfirrman grade'].values[0])\n",
    "            \n",
    "            # Optionally load the image data if needed\n",
    "            image = Image.open(os.path.join(image_dir, filename))\n",
    "            # Resize image to 224x224 pixels\n",
    "            image = image.resize((224,224))\n",
    "            # Convert image to RGB\n",
    "            image = image.convert(\"RGB\")\n",
    "            # Convert the image to numpy array\n",
    "            image_array = np.array(image)\n",
    "            # Normalize array\n",
    "            image_array = preprocess_input(image_array)\n",
    "            image_list.append(image_array)\n",
    "            image_names.append(filename)\n",
    "\n",
    "print(\"Labels have been mapped to each image and stored in the corresponding lists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e4a14b0-d38b-4656-ad24-6525c411a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_np = np.array(image_list)\n",
    "up_endplates_np = np.array(up_endplates)\n",
    "low_endplates_np = np.array(low_endplates)\n",
    "disc_herniation_np = np.array(disc_herniation)\n",
    "disc_narrowing_np = np.array(disc_narrowing)\n",
    "disc_bulging_np = np.array(disc_bulging)\n",
    "spondylolisthesis_np = np.array(spondylolisthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3ff388-b254-4cb0-ba87-3783fb33d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce dimensions\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "up_predictions = Dense(1, activation='sigmoid', name='up_output')(x)\n",
    "low_predictions = Dense(1, activation='sigmoid', name='low_output')(x)\n",
    "herniation_predictions = Dense(1, activation='sigmoid', name='herniation_output')(x)\n",
    "narrowing_predictions = Dense(1, activation='sigmoid', name='narrowing_output')(x)\n",
    "bulging_predictions = Dense(1, activation='sigmoid', name='bulging_output')(x)\n",
    "spondy_predictions = Dense(1, activation='sigmoid', name='spondy_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f32f194-531b-4a98-92ff-6b5c6cf6b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=[up_predictions, low_predictions, herniation_predictions, narrowing_predictions, bulging_predictions, spondy_predictions])\n",
    "model.compile(optimizer='adam', loss={\n",
    "        'up_output': 'binary_crossentropy',\n",
    "        'low_output': 'binary_crossentropy',\n",
    "        'herniation_output': 'binary_crossentropy',\n",
    "        'narrowing_output': 'binary_crossentropy',\n",
    "        'bulging_output': 'binary_crossentropy',\n",
    "        'spondy_output': 'binary_crossentropy'\n",
    "    },          \n",
    "    metrics={\n",
    "        'up_output': 'accuracy',\n",
    "        'low_output': 'accuracy',\n",
    "        'herniation_output': 'accuracy',\n",
    "        'narrowing_output': 'accuracy',\n",
    "        'bulging_output': 'accuracy',\n",
    "        'spondy_output': 'accuracy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44305701-02cf-4ad1-8b54-53e20a484dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - bulging_output_accuracy: 0.5317 - bulging_output_loss: 0.9068 - herniation_output_accuracy: 0.8200 - herniation_output_loss: 0.8007 - loss: 3.9465 - low_output_accuracy: 0.5882 - low_output_loss: 0.7198 - narrowing_output_accuracy: 0.6070 - narrowing_output_loss: 0.7393 - spondy_output_accuracy: 0.9927 - spondy_output_loss: 0.0810 - up_output_accuracy: 0.5919 - up_output_loss: 0.6983 - val_bulging_output_accuracy: 0.5047 - val_bulging_output_loss: 1.0445 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.2044 - val_loss: 3.6598 - val_low_output_accuracy: 0.5327 - val_low_output_loss: 0.7143 - val_narrowing_output_accuracy: 0.5374 - val_narrowing_output_loss: 0.7209 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1500 - val_up_output_accuracy: 0.4533 - val_up_output_loss: 0.8128\n",
      "Epoch 2/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - bulging_output_accuracy: 0.6989 - bulging_output_loss: 0.5984 - herniation_output_accuracy: 0.9481 - herniation_output_loss: 0.1957 - loss: 2.5647 - low_output_accuracy: 0.6986 - low_output_loss: 0.5663 - narrowing_output_accuracy: 0.7166 - narrowing_output_loss: 0.5609 - spondy_output_accuracy: 0.9935 - spondy_output_loss: 0.0374 - up_output_accuracy: 0.6931 - up_output_loss: 0.6061 - val_bulging_output_accuracy: 0.6355 - val_bulging_output_loss: 0.6725 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.2043 - val_loss: 3.1048 - val_low_output_accuracy: 0.5748 - val_low_output_loss: 0.7458 - val_narrowing_output_accuracy: 0.6402 - val_narrowing_output_loss: 0.6394 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1206 - val_up_output_accuracy: 0.5421 - val_up_output_loss: 0.7386\n",
      "Epoch 3/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - bulging_output_accuracy: 0.7574 - bulging_output_loss: 0.4739 - herniation_output_accuracy: 0.9533 - herniation_output_loss: 0.1588 - loss: 2.2172 - low_output_accuracy: 0.7747 - low_output_loss: 0.5026 - narrowing_output_accuracy: 0.7493 - narrowing_output_loss: 0.5105 - spondy_output_accuracy: 0.9936 - spondy_output_loss: 0.0344 - up_output_accuracy: 0.7296 - up_output_loss: 0.5374 - val_bulging_output_accuracy: 0.6682 - val_bulging_output_loss: 0.6529 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.1981 - val_loss: 3.1434 - val_low_output_accuracy: 0.5467 - val_low_output_loss: 0.7644 - val_narrowing_output_accuracy: 0.6402 - val_narrowing_output_loss: 0.6849 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1220 - val_up_output_accuracy: 0.5841 - val_up_output_loss: 0.7545\n",
      "Epoch 4/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - bulging_output_accuracy: 0.7481 - bulging_output_loss: 0.4763 - herniation_output_accuracy: 0.9558 - herniation_output_loss: 0.1406 - loss: 2.1683 - low_output_accuracy: 0.7700 - low_output_loss: 0.5038 - narrowing_output_accuracy: 0.7353 - narrowing_output_loss: 0.5148 - spondy_output_accuracy: 0.9878 - spondy_output_loss: 0.0446 - up_output_accuracy: 0.7855 - up_output_loss: 0.4888 - val_bulging_output_accuracy: 0.5981 - val_bulging_output_loss: 0.8573 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.2672 - val_loss: 3.5303 - val_low_output_accuracy: 0.5374 - val_low_output_loss: 0.7912 - val_narrowing_output_accuracy: 0.6869 - val_narrowing_output_loss: 0.6206 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1251 - val_up_output_accuracy: 0.4626 - val_up_output_loss: 0.8691\n",
      "Epoch 5/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - bulging_output_accuracy: 0.7800 - bulging_output_loss: 0.4430 - herniation_output_accuracy: 0.9444 - herniation_output_loss: 0.1881 - loss: 2.0240 - low_output_accuracy: 0.8219 - low_output_loss: 0.4347 - narrowing_output_accuracy: 0.7626 - narrowing_output_loss: 0.4611 - spondy_output_accuracy: 0.9910 - spondy_output_loss: 0.0373 - up_output_accuracy: 0.7670 - up_output_loss: 0.4597 - val_bulging_output_accuracy: 0.5935 - val_bulging_output_loss: 0.7756 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.2130 - val_loss: 3.4363 - val_low_output_accuracy: 0.5935 - val_low_output_loss: 0.8790 - val_narrowing_output_accuracy: 0.6636 - val_narrowing_output_loss: 0.6429 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1410 - val_up_output_accuracy: 0.5234 - val_up_output_loss: 0.8088\n",
      "Epoch 6/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - bulging_output_accuracy: 0.8119 - bulging_output_loss: 0.4054 - herniation_output_accuracy: 0.9510 - herniation_output_loss: 0.1442 - loss: 1.8793 - low_output_accuracy: 0.7961 - low_output_loss: 0.4283 - narrowing_output_accuracy: 0.7989 - narrowing_output_loss: 0.4113 - spondy_output_accuracy: 0.9873 - spondy_output_loss: 0.0423 - up_output_accuracy: 0.7938 - up_output_loss: 0.4477 - val_bulging_output_accuracy: 0.6308 - val_bulging_output_loss: 0.7462 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.2014 - val_loss: 3.5111 - val_low_output_accuracy: 0.4579 - val_low_output_loss: 0.8716 - val_narrowing_output_accuracy: 0.6355 - val_narrowing_output_loss: 0.6716 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1475 - val_up_output_accuracy: 0.4766 - val_up_output_loss: 0.8802\n",
      "Epoch 7/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - bulging_output_accuracy: 0.8289 - bulging_output_loss: 0.3687 - herniation_output_accuracy: 0.9589 - herniation_output_loss: 0.1026 - loss: 1.5615 - low_output_accuracy: 0.8637 - low_output_loss: 0.3535 - narrowing_output_accuracy: 0.8468 - narrowing_output_loss: 0.3567 - spondy_output_accuracy: 0.9943 - spondy_output_loss: 0.0207 - up_output_accuracy: 0.8480 - up_output_loss: 0.3594 - val_bulging_output_accuracy: 0.6495 - val_bulging_output_loss: 0.7552 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.2084 - val_loss: 3.4941 - val_low_output_accuracy: 0.5654 - val_low_output_loss: 0.8730 - val_narrowing_output_accuracy: 0.6589 - val_narrowing_output_loss: 0.6845 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1275 - val_up_output_accuracy: 0.4907 - val_up_output_loss: 0.8785\n",
      "Epoch 8/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - bulging_output_accuracy: 0.8481 - bulging_output_loss: 0.3644 - herniation_output_accuracy: 0.9624 - herniation_output_loss: 0.1001 - loss: 1.6119 - low_output_accuracy: 0.8515 - low_output_loss: 0.3538 - narrowing_output_accuracy: 0.8284 - narrowing_output_loss: 0.3792 - spondy_output_accuracy: 0.9889 - spondy_output_loss: 0.0257 - up_output_accuracy: 0.8376 - up_output_loss: 0.3887 - val_bulging_output_accuracy: 0.6589 - val_bulging_output_loss: 0.7176 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.2430 - val_loss: 3.7278 - val_low_output_accuracy: 0.5327 - val_low_output_loss: 1.0172 - val_narrowing_output_accuracy: 0.6916 - val_narrowing_output_loss: 0.6698 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1463 - val_up_output_accuracy: 0.4953 - val_up_output_loss: 0.9770\n",
      "Epoch 9/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - bulging_output_accuracy: 0.8786 - bulging_output_loss: 0.2998 - herniation_output_accuracy: 0.9648 - herniation_output_loss: 0.0893 - loss: 1.3730 - low_output_accuracy: 0.8602 - low_output_loss: 0.3261 - narrowing_output_accuracy: 0.8754 - narrowing_output_loss: 0.2959 - spondy_output_accuracy: 0.9900 - spondy_output_loss: 0.0240 - up_output_accuracy: 0.8651 - up_output_loss: 0.3379 - val_bulging_output_accuracy: 0.6449 - val_bulging_output_loss: 0.7189 - val_herniation_output_accuracy: 0.9486 - val_herniation_output_loss: 0.2185 - val_loss: 3.7953 - val_low_output_accuracy: 0.5607 - val_low_output_loss: 1.0894 - val_narrowing_output_accuracy: 0.6822 - val_narrowing_output_loss: 0.6633 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1462 - val_up_output_accuracy: 0.5935 - val_up_output_loss: 1.0251\n",
      "Epoch 10/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - bulging_output_accuracy: 0.8940 - bulging_output_loss: 0.2923 - herniation_output_accuracy: 0.9609 - herniation_output_loss: 0.0898 - loss: 1.2415 - low_output_accuracy: 0.8936 - low_output_loss: 0.2728 - narrowing_output_accuracy: 0.8903 - narrowing_output_loss: 0.2878 - spondy_output_accuracy: 0.9970 - spondy_output_loss: 0.0116 - up_output_accuracy: 0.8970 - up_output_loss: 0.2876 - val_bulging_output_accuracy: 0.6168 - val_bulging_output_loss: 0.8301 - val_herniation_output_accuracy: 0.9439 - val_herniation_output_loss: 0.2097 - val_loss: 4.0504 - val_low_output_accuracy: 0.5888 - val_low_output_loss: 1.1227 - val_narrowing_output_accuracy: 0.6776 - val_narrowing_output_loss: 0.6750 - val_spondy_output_accuracy: 0.9766 - val_spondy_output_loss: 0.1396 - val_up_output_accuracy: 0.6215 - val_up_output_loss: 1.1402\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    image_list_np,            # Input images\n",
    "    [up_endplates_np, low_endplates_np, disc_herniation_np, disc_narrowing_np, disc_bulging_np, spondylolisthesis_np],\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,     # Split 20% of data for validation\n",
    "    verbose=1                 # Set to 1 to see training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3d57a01-4ae1-4846-9f29-fa0a805c5df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "Probability of Up-Endplate: 0.5408105254173279\n",
      "Probability of Low-Endplate: 0.6300442218780518\n",
      "Probability of Disc-Herniation: 0.009400335140526295\n",
      "Probability of Disc-Narrowing: 0.6716626882553101\n",
      "Probability of Disc-Bulging: 0.9579753279685974\n",
      "Probability of Spondylolisthesis: 0.004607596434652805\n"
     ]
    }
   ],
   "source": [
    "test_image_path = 'split_discs/127_t2_SPACE_disc_3.png'\n",
    "\n",
    "# Load, resize, and preprocess the test image\n",
    "img = Image.open(test_image_path).convert('RGB')\n",
    "img_resized = img.resize((224, 224))\n",
    "img_array = np.array(img_resized)\n",
    "\n",
    "# Preprocess the image for ResNet50\n",
    "img_preprocessed = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "img_preprocessed = np.expand_dims(img_preprocessed, axis=0)  # Add batch dimension\n",
    "\n",
    "# Run the prediction\n",
    "predicted_probabilities = model.predict(img_preprocessed)\n",
    "print(f\"Probability of Up-Endplate: {predicted_probabilities[0][0][0]}\")\n",
    "print(f\"Probability of Low-Endplate: {predicted_probabilities[1][0][0]}\")\n",
    "print(f\"Probability of Disc-Herniation: {predicted_probabilities[2][0][0]}\")\n",
    "print(f\"Probability of Disc-Narrowing: {predicted_probabilities[3][0][0]}\")\n",
    "print(f\"Probability of Disc-Bulging: {predicted_probabilities[4][0][0]}\")\n",
    "print(f\"Probability of Spondylolisthesis: {predicted_probabilities[5][0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9b61569-0802-48fd-b5a0-cf2b7eeceac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Image name: 127_t2_SPACE_disc_3.png\n",
      "  Pfirrman Grade: 4\n",
      "  Modic Type: 2\n",
      "  UP Endplate: 1\n",
      "  LOW Endplate: 1\n",
      "  Spondylolisthesis: 0\n",
      "  Disc Herniation: 0\n",
      "  Disc Narrowing: 1\n",
      "  Disc Bulging: 1\n"
     ]
    }
   ],
   "source": [
    "idx = 142\n",
    "print(f\"  Image name: {image_names[idx]}\")\n",
    "print(f\"  Pfirrman Grade: {pfirrman_grades[idx]}\")\n",
    "print(f\"  Modic Type: {modic_types[idx]}\")\n",
    "print(f\"  UP Endplate: {up_endplates[idx]}\")\n",
    "print(f\"  LOW Endplate: {low_endplates[idx]}\")\n",
    "print(f\"  Spondylolisthesis: {spondylolisthesis[idx]}\")\n",
    "print(f\"  Disc Herniation: {disc_herniation[idx]}\")\n",
    "print(f\"  Disc Narrowing: {disc_narrowing[idx]}\")\n",
    "print(f\"  Disc Bulging: {disc_bulging[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "928c9c73-366a-481c-b087-683d308ecbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('binaryIndividualPredictions.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03545059-a330-46a9-9a2e-76eb4e5fc48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
